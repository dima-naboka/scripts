{
  "metadata": {
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "tags": [
      "deleted-recipe-editor"
    ],
    "createdOn": 1648056277662,
    "hide_input": false,
    "modifiedBy": "admin",
    "customFields": {},
    "creator": "admin",
    "versionNumber": 1
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 1,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# -*- coding: utf-8 -*-\nimport dataiku\nimport pandas as pd, numpy as np"
      ],
      "outputs": []
    },
    {
      "execution_count": 2,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ds_name \u003d \u0027SFPD_Reports_partitioned_year_S3_parq\u0027\ncol_name \u003d \u0027IncidntNum\u0027\n\n# dataset \u003d dataiku.Dataset(ds_name)\n# list_partitions \u003d dataset.list_partitions()\noutput_df \u003d pd.DataFrame()\n\nfor partition in dataiku.Dataset(ds_name).list_partitions():\n    print(\u0027calc stats for %s partition\u0027 %partition)\n    dataset \u003d dataiku.Dataset(ds_name)\n    dataset.add_read_partitions(partition)\n    input_df \u003d dataset.get_dataframe()\n    \n    new_row \u003d {\u0027partition_id\u0027:partition,\u0027row_count\u0027:input_df[col_name].count()}\n    #populate final DF with data\n    output_df \u003d output_df.append(new_row,ignore_index\u003dTrue)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "calc stats for 2018 partition\ncalc stats for 2017 partition\ncalc stats for 2016 partition\ncalc stats for 2015 partition\n"
        }
      ]
    },
    {
      "execution_count": 3,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# update DF column types and write output dataset\noutput_df \u003d output_df.astype({\"partition_id\": str, \"row_count\": int})\ncount_partitions_ids \u003d dataiku.Dataset(\"count_partitions_ids\")\ncount_partitions_ids.write_with_schema(output_df)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "4 rows successfully written (ISqDAzXMD5)\n"
        }
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# #####"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "output_df \u003d output_df.astype({\"partition_id\": str, \"row_count\": int})\noutput_df"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "SFPD_Reports_partitioned_year_S3_parq \u003d dataiku.Dataset(\"SFPD_Reports_partitioned_year_S3_parq\")\nSFPD_Reports_partitioned_year_S3_parq.add_read_partitions(\u00272015\u0027)\n\nSFPD_Reports_partitioned_year_S3_parq_df \u003d SFPD_Reports_partitioned_year_S3_parq.get_dataframe()\ncount \u003d SFPD_Reports_partitioned_year_S3_parq_df[\u0027IncidntNum\u0027].count()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "out_df \u003d pd.DataFrame()\npartition\u003d\u00272015\u0027\nrow_count\u003d1\n\nnew_row \u003d {\u0027partition_id\u0027:partition,\u0027val_count\u0027:row_count}\nout_df \u003d out_df.append(new_row,ignore_index\u003dTrue)\n\nprint(out_df)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    }
  ]
}